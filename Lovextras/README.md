# Lovextras 关键词提取工具箱
  
  - ## 使用说明
    
    - 目前包含了两种词向量提取方法，一种基于tf idf算法，另一种基于word2vec模型训练的词向量，2w的语料测试下tf idf远好于word2vec
      
    - word2vec关键词抽取方法传入的并不是文本，而是词向量，即numpy.darray类型，所以返回值中不包含任何文本，而是包含了训练数据的位置信息，可以通过位置信息获取到文本
      
    - 本质上word2vec的关键词提取方法和word2vec没有关系，任何词向量都可以使用该方法，只不过本工具箱内目前提供word2vec......
      
  - ## api
    
    - Tf_Idf(Corpus_path="":str,Corpus=[]:list)  初始化tf idf模型，传入语料，注意传入参数需要是二维矩阵或数组，即由句子->单词的单位组成
      
    - Tf_Idf.train(topn=1:int):  对tf idf模型进行训练，返回传入语料中每一行(每一句或每一篇文本)的topn个set对，set由(关键词,得分)组成
      
    - ExtractionForWordVector(vectors:list,topn=1:int,mode="cosine":str)  使用词向量提取关键词，vectors也请遵循tf-idf的单位结构，mode的参数为"cosine"或"euclidean",即使用余弦距离和欧式距离进行相似度计算
      
    - ExtractionForWordVector.fit()  训练，返回n个list，n为文章篇数，每个list长度为topn，每个topn由一对set组成，set[0]为单词在原语料的句子中的下标,set[1]为得分
      
  - tips:
    
    - 1.tf idf中的得分越高越好，而词向量抽取方法中的得分则是越低越好
      
    - 2.词向量抽取方法依赖与词向量训练的效果，如果你无法保证词向量训练的效果够好，请使用tf idf
      
  - ## 案例
    
    - ### tf idf
      
      - 首先导入必要的包
      ```python
      from Lovextras.lovextras import Tf_Idf
      ```
        
      - 建模并训练
      ```python
      tf_idf = Tf_Idf(Corpus_path='...')
      keywords = tf_idf.train(topn=3)
      ```
        
      - 输出结果(只展示一部分)
      ```python
      for words in keywords:
      print(words)
      ```
        
      ```
      [('陶粒', 174.255281892944), ('筒压强度', 116.17018792862933), ('堆积密度', 116.17018792862933)]
      [('济川煎', 170.96744638552997), ('生物反馈治疗', 170.96744638552997), ('出口梗阻型便秘', 170.96744638552997)]
      [('肝纤维化', 229.4499146350834), ('病人', 166.77593162187938), ('乙肝', 110.49125822688161)]
      [('全自动驾驶', 156.22887342126012), ('场景', 120.37643304746985), ('调度', 120.37643304746985)]
      [('放疗', 109.09114244926955), ('放化疗', 81.71749306363118), ('同步放化疗', 81.71749306363118)]
      [('模糊可靠度', 124.12705011552175), ('模拟方法', 82.75136674368116), ('参数概率分布', 82.75136674368116)]
      [('澄碧河水库', 221.00669898617286), ('生态系统服务功能价值', 147.33779932411525), ('水库', 147.33779932411525)]
      [('盐胁迫', 298.31356900191236), ('叶绿素合成', 186.44598062619522), ('叶绿素含量', 114.92729410293417)]
      [('龙滩珍珠李', 161.80847604344797), ('甜味剂', 107.87231736229866), ('糖煮', 107.87231736229866)]
      [('抗晚疫病', 503.40414769072703), ('樱桃番茄', 201.36165907629083), ('田间抗性', 100.68082953814542)]
      [('罗汉果甜苷', 140.48487842531918), ('相对表达量', 76.0060709313708), ('人工授粉', 70.24243921265959)]
      [('报春石斛', 257.05743711866916), ('蔗糖', 166.91232625762964), ('种子无菌萌发', 128.52871855933458)]
      [('植物', 225.22013906721), ('第二信使', 118.4480347507593), ('嫌钙植物', 118.4480347507593)]
      [('蒎烯', 326.53242012371487), ('产脂力', 285.7158676082505), ('树脂酸', 204.0827625773218)]
      [('腰椎结核', 232.34037585725866), ('N浓度', 123.98246966412106), ('凋亡促进因子', 58.085093964314666)]
      [('电针', 373.56568257659967), ('灵龟八法开穴', 233.4785516103748), ('辨证取穴', 161.80847604344797)]
      ```
        
    - ### 词向量提取
      
      - 首先导入必要的包,这里我们一起训练word2vec
      ```python
      from Vermit.vermit import Word2Vec
      from Lovextras.lovextras import ExtractionForWordVector
      ```
        
      - 训练word2vec
      ```python
      print("building word2vec model......")
      w2v = Word2Vec(Corpus_path='...',word_dim=400,window=5,epochs=5,sample=1e-4)
      w2v.train(mode='cbow')
      ```
        
      - 进行词向量抽取训练,本次我们抽取100条文本的关键词
      ```python
      print('take word2vec model to extraction keywords')
      corpus = []
      with open(os.path.dirname('...','r',encoding="utf-8") as f:
          for i in range(100):
              corpus.append(f.readline().strip('\n'))
      corpus_vectors = []
      for sentence in corpus:
          temp = []
          for word in sentence.split(" "):
              if word in w2v:
                  temp.append(w2v[word])
          corpus_vectors.append(temp)
      extra = ExtractionForWordVector(corpus_vectors,topn=3)
      center_words = extra.fit()
      ```
        
      - 获取结果并映射回原100条文本中
      ```python
      for words_index,sentence in zip(center_words,corpus):
      for word_index in words_index:
          print(sentence.split(" ")[word_index[0]])
      print(words_index)
      ```
        
      ```
      建筑垃圾
      研制
      主要原料
      [(0, 8.624367997533966e-09), (13, 8.624367997533966e-09), (4, 1.4861807990646225)]
      病人
      N
      生物反馈疗法
      [(19, 5.393543038190174e-06), (12, 9.616170002169078e-06), (34, 1.529405623235114e-05)]
      表法
      N
      收治
      [(21, 5.314175206105887e-06), (42, 5.314175206105887e-06), (13, 1.157616880242962e-05)]
      权重比
      地铁
      方法
      [(52, 7.707278287916175e-06), (24, 1.539328561195319e-05), (30, 1.6604780720963497e-05)]
      放化疗
      模式
      调强
      [(22, 7.5028553815359444e-06), (40, 8.520092817709823e-06), (52, 1.3886604841473194e-05)]
      最大熵原理
      模糊可靠度
      考虑
      [(40, 4.706954091382443e-06), (52, 4.706954091382443e-06), (55, 8.761775803667327e-06)]
      估算
      生态安全指数
      处于
      [(12, 5.399136824069117e-06), (30, 9.714712174146989e-06), (31, 1.3337809518843002e-05)]
      叶绿素
      气体交换参数
      上升
      [(23, 4.990775979707429e-06), (62, 4.990775979707429e-06), (65, 9.806688826441423e-06)]
      条件
      配方
      硬化护色
      [(19, 5.372189411323447e-06), (14, 8.415650936899333e-06), (41, 8.415650936899333e-06)]
      晚疫病抗性
      以期
      樱桃番茄
      [(13, 5.025297953320518e-06), (14, 8.733275196570744e-06), (7, 8.769433059385712e-06)]
      代谢
      葫芦二烯醇合酶
      以期
      [(28, 4.9707395056719506e-06), (19, 5.621568440750124e-06), (22, 7.538879467472448e-06)]
      原球茎诱导
      培养基
      以期
      [(25, 7.615243066028121e-06), (40, 7.615243066028121e-06), (12, 1.3476305729454019e-05)]
      作为
      生理生化
      导致
      [(0, 7.010265073104094e-06), (15, 7.010265073104094e-06), (18, 7.010265073104094e-06)]
      树脂酸
      海松酸
      海松酸
      [(40, 5.719676920312722e-06), (43, 5.719676920312722e-06), (99, 9.488743197838545e-06)]
      选取
      N
      对照组
      [(23, 1.7788823878372995e-06), (25, 1.7788823878372995e-06), (27, 1.7788823878372995e-06)]
      检测
      产后
      N
      [(30, 3.777338265842367e-06), (32, 3.777338265842367e-06), (42, 3.777338265842367e-06)]
      ```
        
      - 可以看到在词向量训练效果和文本清洗一般的情况下，后期抽取关键词效果也并不好
